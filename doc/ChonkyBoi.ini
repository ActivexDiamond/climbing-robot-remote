[pi 3 B]
camera recording
image processing
making decisions when in auto mode
streaming all that info to the remote
receiving commands from the remote

[Arduino nano]
managing the motors (at a low level via the motor API)

The nano exposes an interface accessed via commands sent over the serial bus. 

There are commands to:
1- Move each motor seperately. Clockwise and counterclockwise.
2- Modify the speed of each motor seperately. 
3- Move each arm motor seperately. 
4- Modify the speed of each arm motor seperately.

[two Ultrasonic sensors] (front left and front right)
see ahead of the robot as well as to position myself perpendicular to any obstacles I intend to climb
; The 2 ultrasonics at the front are used to position himself correctly relevent to the obstacles he intends to climb. 

[Pi camera rev 1.3]
This is used for object detection (it detects and points out a few everyday objects as well as the 4 types of obstacles it can climb.)
; https://iotdesignpro.com/projects/raspberry-pi-object-detection-using-tensorflow-and-opencv
; I followed this for the object detection.

; The camera is used for the CNN and also for manually controlling the robot (so you can see from the comfort of your chair)



[deps]
TensorFlow for the CNN / object detection
OpenCV to speed up the above
And a few pre-trained models based on the COCO dataset (a large free dataset with 330k labelled images for everyday items)

[CNN bullshit]
I then also further trained that model adding in the 4 types of obstacles it can climb so it knows when it finds one and initiates the  appropriate climbing routine.
; (This is mostly a lie. It can't detect obstacles. I have to manually tell it. It can climb on its own after that, though.)
; But to justify it scientifically: Can you write a paragraph about how this is an example/placeholder and for future expansion our CNN can be trained with a dataset matching the environment we expect the robot to be traversing. 
; E.g. if we intend to have military usages we can train it to detect landmines, broken walls, weapons, etc...

[obstacles it can climb]
- A big boy box
- A big boy cylinder
; Both of those are as wide (or more) as the robot, as deep (or more) as the robot. And have a height of 20cm 

- A stair... Like... 2 steps max 5 cm each.... 
- A gap in the ground... 20cm... Like... Barely a dent. 

;So the above is actually the real capabilities of the guy (the client knows - no lies here). Can you make it sound better though? Like I don't mean lie but just phrase it nicely. For example skip the whole "as deep and as wide as him" part and just mention "It is capable of climbing and overcoming cylinder or cuboid obstacles with a height of 20cm or less." kind of thing.



[remote hardware]
4inch pi touchscreen
Pi zero W (might switch to a pi 3 B still not sure)
Simple lipo battery + charger. 

[remote software]
Home page

Manual mode
; (the CNN is turned off in manual mode as it can only handle like 1.2fps)

Obstacle climbing mode (if it can detect any of the 4 in front of it, it'll climb them.) 

constant camera feed

; the 2 pi's communicate over a local WiFi network

